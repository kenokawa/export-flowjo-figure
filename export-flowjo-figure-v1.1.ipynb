{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "from os import path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HARD-CODED VARIABLES\n",
    "\n",
    "#calculate cells/uL\n",
    "#True if inputting blood volumes, countbright bead data, and absolute counts\n",
    "#False if input data type is anything else\n",
    "calc_cells_ul = True\n",
    "\n",
    "#show groups in csv file True or False\n",
    "#also orders samples in csv file by group \n",
    "show_groups_csv = True\n",
    "\n",
    "#show gate name after each timepoint in csv file True or False\n",
    "#true is recommended to confirm the identity of the data\n",
    "show_gate_name_csv = True\n",
    "\n",
    "#number of countbright beads added (1uL = 1000beads)\n",
    "countbeads_input = 25000\n",
    "\n",
    "#significant p-value\n",
    "sig_p_value = 0.05\n",
    "\n",
    "#plot style\n",
    "plot_style_choice = 'ggplot'\n",
    "\n",
    "#error bar choice: 1 for STDEV, 2 for SEM\n",
    "error_bar_choice = 1\n",
    "\n",
    "#axis labels for plot to be exported\n",
    "x_axis_label = 'Days post infection'\n",
    "y_axis_label = 'Cells/uL blood'\n",
    "\n",
    "#removes x number chars from end of sample name\n",
    "#ex. DC60_506_001.fcs changed to DC60_506 if end_chars_del = 8\n",
    "end_chars_del = 8\n",
    "\n",
    "#keep x number chars from end of sample name, deletes rest\n",
    "#this step happens after end_chars_del\n",
    "#ex. DC60_506 is changed to 506 if chars_to_keep = 3\n",
    "chars_to_keep = 3\n",
    "\n",
    "#day min and day max are terrible and I will try to fix this\n",
    "day_min = -500\n",
    "day_max = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explain inputs for script\n",
    "\n",
    "print('''This script requires the installation of Anaconda and python3.6 or later.\n",
    "The input csv files must be named and formatted correctly.\n",
    "The order of gates in the csv files must be the same for all csv files.''')\n",
    "\n",
    "#ask for user inputs\n",
    "print('Enter study name (Ex. DC60)')\n",
    "study_name = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compatibility check\n",
    "#determine number of rows in csv files\n",
    "row_list = []\n",
    "\n",
    "for day in range(day_min,day_max):\n",
    "    if path.exists(f'{day}_{study_name}.csv'):\n",
    "\n",
    "        #read flowjo export csv file\n",
    "        df = pd.read_csv(f'{day}_{study_name}.csv')\n",
    "        flowjo_file_length = len(df.columns)\n",
    "        row_list.append(len(df.columns))       \n",
    "\n",
    "print(f'Flowjo file row lengths are: \\n{row_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read groups csv file as df and create blank dictionary\n",
    "if path.exists(f'groups_{study_name}.csv'):\n",
    "    groups_df = pd.read_csv(f'groups_{study_name}.csv')\n",
    "    groups_dictionary = {}\n",
    "\n",
    "    #extract group name and samples from each column in df\n",
    "    #add group name as key and samples as items in dictionary\n",
    "    for group_column in range(len(groups_df.columns)):\n",
    "        group_name = groups_df.columns[group_column].upper()\n",
    "        items = groups_df.iloc[:,group_column]\n",
    "        items = items.dropna()\n",
    "        items = items.tolist()\n",
    "        items = list(map(int,items))\n",
    "        items = list(map(str,items))\n",
    "        groups_dictionary.update({group_name:items})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    print('''What statistics would you like to run?\n",
    "    1 None\n",
    "    2 scipy.stats.ttest_ind (Independent t-test)\n",
    "    3 scipy.stats.f_oneway (One way ANOVA)\n",
    "    4 scipy.stats.wilcoxon (Wilcoxon signed-rank test default settings)''')\n",
    "    statistics_selection = int(input())\n",
    "    if len(groups_dictionary) != 2 and (statistics_selection == 2 or statistics_selection ==4):\n",
    "        print('Number of groups not compatible with statistical analysis')\n",
    "    if statistics_selection > 0 and statistics_selection <5:\n",
    "         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if calculate cells/uL is True, dont make outputs of the first two columns\n",
    "#first two columns should contain blood volume and countbright beads\n",
    "if calc_cells_ul == True:\n",
    "    cols_to_skip = 2\n",
    "if calc_cells_ul == False:\n",
    "    cols_to_skip = 0\n",
    "    \n",
    "export_df_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gate_num in range (cols_to_skip,(row_list[0]-1)):\n",
    "#for gate_num in range (cols_to_skip,20):\n",
    "    partial_df = pd.DataFrame([])\n",
    "    export_df = pd.DataFrame([])\n",
    "    export_df_csv = pd.DataFrame([])\n",
    "    df = pd.DataFrame([])\n",
    "    significant = False\n",
    "    for day in range(day_min,day_max):\n",
    "        if path.exists(f'{day}_{study_name}.csv'):\n",
    "            \n",
    "            #read flowjo export csv file\n",
    "            df = pd.read_csv(f'{day}_{study_name}.csv')\n",
    "            \n",
    "            #set column containing sample ID as index\n",
    "            df.rename(columns={ df.columns[0]: 'Mouse ID' }, inplace = True)   \n",
    "            df = df.set_index('Mouse ID')\n",
    "            \n",
    "            #clean and extract gate name to use for file name\n",
    "            df.columns = [x.strip().replace('/','_') for x in df.columns]\n",
    "            df.columns = [x.strip().replace(' | Count','') for x in df.columns]\n",
    "            gate_name = df.columns[gate_num]\n",
    "            \n",
    "            #remove any rows that do not have study name in sample ID\n",
    "            #CONSIDER REMOVING THIS AND HAVING USER CLEAN DATA THEMSELVES\n",
    "            \n",
    "            df = df.loc[df.index.str.contains(study_name)]\n",
    "            \n",
    "            #clean sample ID labels\n",
    "            df.index = df.index.map(lambda x: str(x)[:-end_chars_del])\n",
    "            df.index = df.index.map(lambda x: str(x)[-chars_to_keep:])\n",
    "            \n",
    "            #transpose\n",
    "            df = df.transpose()\n",
    "            \n",
    "            #select column that contains \n",
    "            partial_df = df.iloc[gate_num]\n",
    "            partial_df = partial_df.astype('float64')\n",
    "            \n",
    "            if calc_cells_ul == True:\n",
    "                #calculate cells/uL blood\n",
    "                countbeads_df = df.iloc[1]\n",
    "                blood_df = df.iloc[0]\n",
    "                countbeads_df = countbeads_df.astype('float64')\n",
    "                blood_df = blood_df.astype('float64')\n",
    "                partial_df = (partial_df/countbeads_df)*(countbeads_input/blood_df)\n",
    "            \n",
    "            #create dictionary specific to timepoint to run stats\n",
    "            #key = group name, value = cells/uL\n",
    "            \n",
    "            while True:\n",
    "                if statistics_selection == 1:\n",
    "                    break\n",
    "                timepoint_dictionary = {}\n",
    "                for k in groups_dictionary.keys():\n",
    "                    timepoint_df = partial_df.reindex(groups_dictionary[k])\n",
    "                    timepoint_df = timepoint_df.tolist()\n",
    "                    timepoint_dictionary.update({k:timepoint_df})\n",
    "\n",
    "                #independent ttest\n",
    "                if statistics_selection == 2:\n",
    "                    throwaway, p_value = stats.ttest_ind(*(timepoint_dictionary.values()), nan_policy = 'omit')\n",
    "                    p_val_name = 'p_val_ttest_ind'\n",
    "                #one way anova\n",
    "                if statistics_selection == 3:\n",
    "                    throwaway, p_value = stats.f_oneway(*timepoint_dictionary.values())\n",
    "                    p_val_name = 'p_val_f_oneway'\n",
    "                #wilcoxon\n",
    "                if statistics_selection == 4:\n",
    "                    throwaway, p_value = stats.wilcoxon(*(timepoint_dictionary.values()))\n",
    "                    p_val_name = 'p_val_wilcoxon'\n",
    "                    \n",
    "                p_value_series = pd.Series(p_value)\n",
    "                p_value_series.index = [p_val_name]\n",
    "                partial_df = pd.concat([p_value_series,partial_df])\n",
    "                break\n",
    "\n",
    "            #rename gate to day\n",
    "            if show_gate_name_csv == True:\n",
    "                partial_df_csv = partial_df.rename(f'{day}_{gate_name}')\n",
    "            else:\n",
    "                partial_df_csv = partial_df.rename(day)\n",
    "            partial_df = partial_df.rename(day)\n",
    "                \n",
    "            #append to df that will be exported\n",
    "            export_df = pd.concat([export_df,partial_df], axis =1)\n",
    "            export_df_csv = pd.concat([export_df_csv,partial_df_csv], axis =1)\n",
    "    \n",
    "    #transpose and export dataframe to csv file\n",
    "    export_df = export_df.transpose()\n",
    "    \n",
    "    export_df_dic.update({gate_name:export_df})\n",
    "    #add a group_id column    \n",
    "    if show_groups_csv == True and path.exists(f'groups_{study_name}.csv') == True:\n",
    "        export_group_series = pd.Series([], dtype = 'object')\n",
    "        for col in range(len(groups_df.columns)):\n",
    "            group_name_series = [groups_df.columns[col]]\n",
    "            group_series = groups_df.iloc[:,col]\n",
    "            group_series = group_series.dropna()\n",
    "            group_series = group_series.astype('int64')\n",
    "            group_series = group_series.astype(str)\n",
    "            group_name_series = group_name_series*len(group_series)\n",
    "            partial_series = pd.Series(group_name_series)\n",
    "            partial_series.index = group_series\n",
    "            export_group_series = pd.concat([export_group_series, partial_series])\n",
    "        export_group_series.name = 'Group'\n",
    "        export_df_csv = pd.concat([export_group_series, export_df_csv], axis = 1)\n",
    "    \n",
    "    #transpose\n",
    "    export_df_csv = export_df_csv.transpose()\n",
    "    \n",
    "    if statistics_selection == 1:\n",
    "        export_df_csv.to_csv(f'{study_name}_{gate_name}.csv')\n",
    "    \n",
    "    #move p_value to first column\n",
    "    if statistics_selection != 1:\n",
    "        first_col = export_df_csv.pop(p_val_name)\n",
    "        export_df_csv.insert(0, p_val_name,first_col)\n",
    "    \n",
    "    #Significant = True if any p-value for gate is < 0.05\n",
    "        p_value_list = export_df_csv[p_val_name]\n",
    "        p_value_list = p_value_list.tolist()\n",
    "        if any (p < sig_p_value for p in p_value_list):\n",
    "            significant = True\n",
    "    \n",
    "        if significant == True:\n",
    "            export_df_csv.to_csv(f'{study_name}_{gate_name}_SIGNIFICANT.csv')\n",
    "        else:\n",
    "            export_df_csv.to_csv(f'{study_name}_{gate_name}.csv')\n",
    "                             \n",
    "    days_x = pd.Series(export_df.index.values.tolist())\n",
    "    \n",
    "    for k in groups_dictionary.keys():\n",
    "        group_df = export_df.loc[:,groups_dictionary[k]]\n",
    "        group_mean = group_df.mean(axis=1, skipna = True)\n",
    "        if error_bar_choice == 1:\n",
    "            group_error = group_df.std(axis=1, skipna = True)\n",
    "        if error_bar_choice == 2:\n",
    "            group_error = group_df.sem(axis=1, skipna = True)\n",
    "        plt.errorbar(days_x, group_mean, yerr = group_error, capsize = 2, label = k)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(study_name+' '+gate_name)\n",
    "    plt.xlabel(x_axis_label)\n",
    "    plt.ylabel(y_axis_label)\n",
    "    plt.tight_layout\n",
    "    plt.style.use(plot_style_choice)\n",
    "    if significant == True:\n",
    "        plt.savefig((f'{study_name}_{gate_name}_SIGNIFICANT.png'))\n",
    "    else:\n",
    "        plt.savefig((f'{study_name}_{gate_name}.png'))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_pop_list = []\n",
    "print('Enter cell populations to plot. Enter d when done')\n",
    "while True:\n",
    "    cell_pop_name = input()\n",
    "    if cell_pop_name == 'd':\n",
    "        break\n",
    "    if cell_pop_name in export_df_dic.keys():\n",
    "        cell_pop_list.append(cell_pop_name)\n",
    "    else:\n",
    "        print('Cell population not found, please try again with correct formatting')\n",
    "\n",
    "print('Enter group to plot. Group must be designated in groups_xx.csv')\n",
    "while True:\n",
    "    group_name = input()\n",
    "    if group_name.upper() in groups_dictionary.keys():\n",
    "        break\n",
    "    print('Group not in groups_xx.csv')\n",
    "print('Please enter plot title name')\n",
    "plot_title = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_pop in cell_pop_list:\n",
    "    cell_pop_df = export_df_dic[cell_pop]\n",
    "    days_x = pd.Series(cell_pop_df.index.values.tolist())\n",
    "    cell_pop_mean = cell_pop_df.mean(axis=1, skipna = True)\n",
    "    cell_pop_std = cell_pop_df.std(axis=1, skipna = True)\n",
    "    plt.errorbar(days_x, cell_pop_mean, yerr = cell_pop_std, capsize = 2, label = cell_pop)\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel(x_axis_label)\n",
    "plt.ylabel(y_axis_label)\n",
    "plt.title(plot_title)\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.savefig((f'{plot_title}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
